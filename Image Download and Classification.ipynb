{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Download and Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ml2-picme/PicMe/blob/imagenet_tree_search/Image%20Download%20and%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWATd4KNHBwU",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZhkZPmugh1t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "03d577a3-86da-456b-ec2c-451260788773"
      },
      "source": [
        "import sys\n",
        "\n",
        "!rm -r PicMe\n",
        "!git clone https://github.com/ml2-picme/PicMe.git\n",
        "\n",
        "sys.path.append(\"/content/PicMe\")\n",
        "\n",
        "from imagenet_processing_script import *"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'PicMe'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/98)   \u001b[K\rremote: Counting objects:   2% (2/98)   \u001b[K\rremote: Counting objects:   3% (3/98)   \u001b[K\rremote: Counting objects:   4% (4/98)   \u001b[K\rremote: Counting objects:   5% (5/98)   \u001b[K\rremote: Counting objects:   6% (6/98)   \u001b[K\rremote: Counting objects:   7% (7/98)   \u001b[K\rremote: Counting objects:   8% (8/98)   \u001b[K\rremote: Counting objects:   9% (9/98)   \u001b[K\rremote: Counting objects:  10% (10/98)   \u001b[K\rremote: Counting objects:  11% (11/98)   \u001b[K\rremote: Counting objects:  12% (12/98)   \u001b[K\rremote: Counting objects:  13% (13/98)   \u001b[K\rremote: Counting objects:  14% (14/98)   \u001b[K\rremote: Counting objects:  15% (15/98)   \u001b[K\rremote: Counting objects:  16% (16/98)   \u001b[K\rremote: Counting objects:  17% (17/98)   \u001b[K\rremote: Counting objects:  18% (18/98)   \u001b[K\rremote: Counting objects:  19% (19/98)   \u001b[K\rremote: Counting objects:  20% (20/98)   \u001b[K\rremote: Counting objects:  21% (21/98)   \u001b[K\rremote: Counting objects:  22% (22/98)   \u001b[K\rremote: Counting objects:  23% (23/98)   \u001b[K\rremote: Counting objects:  24% (24/98)   \u001b[K\rremote: Counting objects:  25% (25/98)   \u001b[K\rremote: Counting objects:  26% (26/98)   \u001b[K\rremote: Counting objects:  27% (27/98)   \u001b[K\rremote: Counting objects:  28% (28/98)   \u001b[K\rremote: Counting objects:  29% (29/98)   \u001b[K\rremote: Counting objects:  30% (30/98)   \u001b[K\rremote: Counting objects:  31% (31/98)   \u001b[K\rremote: Counting objects:  32% (32/98)   \u001b[K\rremote: Counting objects:  33% (33/98)   \u001b[K\rremote: Counting objects:  34% (34/98)   \u001b[K\rremote: Counting objects:  35% (35/98)   \u001b[K\rremote: Counting objects:  36% (36/98)   \u001b[K\rremote: Counting objects:  37% (37/98)   \u001b[K\rremote: Counting objects:  38% (38/98)   \u001b[K\rremote: Counting objects:  39% (39/98)   \u001b[K\rremote: Counting objects:  40% (40/98)   \u001b[K\rremote: Counting objects:  41% (41/98)   \u001b[K\rremote: Counting objects:  42% (42/98)   \u001b[K\rremote: Counting objects:  43% (43/98)   \u001b[K\rremote: Counting objects:  44% (44/98)   \u001b[K\rremote: Counting objects:  45% (45/98)   \u001b[K\rremote: Counting objects:  46% (46/98)   \u001b[K\rremote: Counting objects:  47% (47/98)   \u001b[K\rremote: Counting objects:  48% (48/98)   \u001b[K\rremote: Counting objects:  50% (49/98)   \u001b[K\rremote: Counting objects:  51% (50/98)   \u001b[K\rremote: Counting objects:  52% (51/98)   \u001b[K\rremote: Counting objects:  53% (52/98)   \u001b[K\rremote: Counting objects:  54% (53/98)   \u001b[K\rremote: Counting objects:  55% (54/98)   \u001b[K\rremote: Counting objects:  56% (55/98)   \u001b[K\rremote: Counting objects:  57% (56/98)   \u001b[K\rremote: Counting objects:  58% (57/98)   \u001b[K\rremote: Counting objects:  59% (58/98)   \u001b[K\rremote: Counting objects:  60% (59/98)   \u001b[K\rremote: Counting objects:  61% (60/98)   \u001b[K\rremote: Counting objects:  62% (61/98)   \u001b[K\rremote: Counting objects:  63% (62/98)   \u001b[K\rremote: Counting objects:  64% (63/98)   \u001b[K\rremote: Counting objects:  65% (64/98)   \u001b[K\rremote: Counting objects:  66% (65/98)   \u001b[K\rremote: Counting objects:  67% (66/98)   \u001b[K\rremote: Counting objects:  68% (67/98)   \u001b[K\rremote: Counting objects:  69% (68/98)   \u001b[K\rremote: Counting objects:  70% (69/98)   \u001b[K\rremote: Counting objects:  71% (70/98)   \u001b[K\rremote: Counting objects:  72% (71/98)   \u001b[K\rremote: Counting objects:  73% (72/98)   \u001b[K\rremote: Counting objects:  74% (73/98)   \u001b[K\rremote: Counting objects:  75% (74/98)   \u001b[K\rremote: Counting objects:  76% (75/98)   \u001b[K\rremote: Counting objects:  77% (76/98)   \u001b[K\rremote: Counting objects:  78% (77/98)   \u001b[K\rremote: Counting objects:  79% (78/98)   \u001b[K\rremote: Counting objects:  80% (79/98)   \u001b[K\rremote: Counting objects:  81% (80/98)   \u001b[K\rremote: Counting objects:  82% (81/98)   \u001b[K\rremote: Counting objects:  83% (82/98)   \u001b[K\rremote: Counting objects:  84% (83/98)   \u001b[K\rremote: Counting objects:  85% (84/98)   \u001b[K\rremote: Counting objects:  86% (85/98)   \u001b[K\rremote: Counting objects:  87% (86/98)   \u001b[K\rremote: Counting objects:  88% (87/98)   \u001b[K\rremote: Counting objects:  89% (88/98)   \u001b[K\rremote: Counting objects:  90% (89/98)   \u001b[K\rremote: Counting objects:  91% (90/98)   \u001b[K\rremote: Counting objects:  92% (91/98)   \u001b[K\rremote: Counting objects:  93% (92/98)   \u001b[K\rremote: Counting objects:  94% (93/98)   \u001b[K\rremote: Counting objects:  95% (94/98)   \u001b[K\rremote: Counting objects:  96% (95/98)   \u001b[K\rremote: Counting objects:  97% (96/98)   \u001b[K\rremote: Counting objects:  98% (97/98)   \u001b[K\rremote: Counting objects: 100% (98/98)   \u001b[K\rremote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 250 (delta 51), reused 0 (delta 0), pack-reused 152\u001b[K\n",
            "Receiving objects: 100% (250/250), 11.69 MiB | 25.57 MiB/s, done.\n",
            "Resolving deltas: 100% (126/126), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5024YJyM7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expandResultsByImageNetTreeSearch(synsetId, localPath, modelName, predicationProbability):\n",
        "  results = getWords(synsetId)\n",
        "  \n",
        "  cnx = mysql.connector.connect(user='ml2', password='ml2@hsOg#2019!',\n",
        "                              host='192.52.33.218',\n",
        "                              database='ml2')\n",
        "  cursor = cnx.cursor()\n",
        "  add_result = (\"insert ignore into results (local_path, model, prediction_class, prediction_probability) values (%s, %s, %s, %s)\")\n",
        "  \n",
        "  for result in results:\n",
        "    data_result = (localPath, modelName, result, float(predictedPropability))\n",
        "    cursor.execute(add_result, data_result)\n",
        "    result_id = cursor.lastrowid\n",
        "        \n",
        "    print(result_id, \" | \", fileName, \" | \", modelName, \" | \", predictedClass, \" | \", predictedPropability)\n",
        "       \n",
        "    cnx.commit()\n",
        "        \n",
        "  cursor.close()\n",
        "  cnx.close()\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "398aFKJTvUoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import urllib.request\n",
        "\n",
        "def downloadFileFromUrl(URL, localPath):\n",
        "  print(\"Lade \", URL, \" nach \", localPath + \" herunter\")\n",
        "  with urllib.request.urlopen(URL) as url:\n",
        "    with open(localPath, 'wb') as f:\n",
        "      f.write(url.read())\n",
        "  load_img(localPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPloOvoFfV0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFileNameFromPath(path):\n",
        "  filename = path.split(\"/\")[len(path.split(\"/\")) - 1]\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvdJC02-ym56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def createLocalDirectory(dir):\n",
        "  \n",
        "  print(\"Erstelle lokales Verzeichnis:\", dir, end='\\t')\n",
        "  \n",
        "  try:  \n",
        "    os.makedirs(dir)\n",
        "\n",
        "  except OSError:  \n",
        "    print (\" - Failed\")\n",
        "  else:\n",
        "    print(\" - OK\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQwnQjoAUzlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def deleteLocalFiles(dir):\n",
        "  try:\n",
        "    print(\"Delete local files\", end='')  \n",
        "    shutil.rmtree(dir) \n",
        "    print(\" - OK\")\n",
        "  except OSError:\n",
        "    print(\" - Failed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J20r1OB-DeU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def findFilesInPath(dir, extensions):\n",
        "\n",
        "  files = []\n",
        "  \n",
        "  # r=root, d=directories, f = files\n",
        "  for r, d, f in os.walk(dir):\n",
        "    for file in f:\n",
        "      for extension in extensions:\n",
        "        if file.lower().endswith(extension.lower()):\n",
        "            files.append(os.path.join(r, file))\n",
        "            break\n",
        "            \n",
        "  return files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5htsSXuNp-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def prepareImagesForClassification(files, sizeX, sizeY):\n",
        "  images = []\n",
        "  \n",
        "  for file in files:\n",
        "    try:\n",
        "      image = Image.open(file)\n",
        "      image = image.resize((sizeX, sizeY), Image.LANCZOS)\n",
        "      image = image.convert(\"RGB\")\n",
        "      \n",
        "      image = np.asarray(image)\n",
        "      images.append(image)\n",
        "    except OSError:\n",
        "      pass\n",
        "  \n",
        "  images = np.asarray(images)\n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcmDx_BHR9uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifyImages(preparedImages, preprocess_input_function, decode_predictions_function, model):\n",
        "  \n",
        "  # preprocess the images to fit to the model\n",
        "  images_preprocessed = preprocess_input_function(preparedImages)\n",
        "  \n",
        "  # use the model to classifi the images\n",
        "  images_pred = model.predict(images_preprocessed, verbose=1)\n",
        "  \n",
        "  pred_results = decode_predictions_function(images_pred)\n",
        "  \n",
        "  return pred_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN2eHfoIS_No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def printClassificationResults(images, predictedClasses):\n",
        "  \n",
        "  for i in range(len(images)):\n",
        "    plt.figure()\n",
        "    plt.imshow(images[i])\n",
        "    plt.title(predictedClasses[i])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znYMR5HZbLCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compareResults(fileNames, resulsList, modelList, threshold):\n",
        "  \n",
        "  for i in range(len(fileNames)):\n",
        "    print(\"Comparing the Results for File: \" + fileNames[i])\n",
        "    \n",
        "    for j in range(5):\n",
        "      for k in range(len(modelList)):\n",
        "        resultToPrint = resultsList[k][i][j]\n",
        "        \n",
        "        # Setze 5% als Threshold\n",
        "        if(resultToPrint is not None and resultToPrint[2] > threshold):\n",
        "          print(\" > \", (j+1), \". Platz @ \", modelList[k], \" : \", resultsList[k][i][j])\n",
        "        else:\n",
        "          print(\" > \", (j+1), \". Platz @ \", modelList[k], \" : \", \"--- Threshold-Filter ---\")\n",
        "      \n",
        "      print(\"=================================================================\")\n",
        "      \n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdV9RhtdUyks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateCsvForModelComparison(fileNames, resulsList, modelList):\n",
        "  allModelCSVs = []\n",
        "  \n",
        "  for k in range(len(modelList)):\n",
        "    modelCSV = modelList[k]\n",
        "    \n",
        "    for i in range(len(fileNames)):\n",
        "      modelCSV += \";\" + getFileNameFromPath(fileNames[i])\n",
        "      \n",
        "    modelCSV += \"\\n\"\n",
        "    \n",
        "    for j in range(5):\n",
        "      modelCSV += str(j+1) + \".Platz\"\n",
        "      \n",
        "      for i in range(len(fileNames)):\n",
        "        modelCSV += \";\" + str(resultsList[k][i][j][1])\n",
        "        \n",
        "      modelCSV += \"\\n\"\n",
        "      \n",
        "    allModelCSVs.append(modelCSV)\n",
        "        \n",
        "  return allModelCSVs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grH2Hwr65Tvc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5e123403-39ff-4e0e-9a44-7e0cf6bf9d2d"
      },
      "source": [
        "# MySQL Part -> Writing Image Classification Results to DB\n",
        "!pip install mysql-connector-python-rf\n",
        "\n",
        "import mysql.connector\n",
        "\n",
        "def storeResultsToDB(fileNames, resultsList, modelList):\n",
        "  \n",
        "  cnx = mysql.connector.connect(user='ml2', password='ml2@hsOg#2019!',\n",
        "                              host='192.52.33.218',\n",
        "                              database='ml2')\n",
        "  cursor = cnx.cursor()\n",
        "  add_result = (\"insert ignore into results (local_path, model, prediction_class, prediction_probability) values (%s, %s, %s, %s)\")\n",
        "  \n",
        "  for k in range(len(modelList)):\n",
        "    \n",
        "    print(\"==== other model =====\")\n",
        "    \n",
        "    for i in range(len(fileNames)):\n",
        "      \n",
        "      print(\"==== other file =====\")\n",
        "      \n",
        "      for j in range(5):\n",
        "        \n",
        "        fileName = fileNames[i]\n",
        "        modelName = modelList[k]\n",
        "        predictedClassSynsetId = resultsList[k][i][j][0]\n",
        "        predictedClass = resultsList[k][i][j][1]\n",
        "        predictedPropability = resultsList[k][i][j][2]\n",
        "  \n",
        "        #print(fileName)\n",
        "        #print(modelName)\n",
        "        #print(predictedClass)\n",
        "        #print(predictedPropability)\n",
        "        #print(\"==============\")\n",
        "        \n",
        "        data_result = (fileName, modelName, predictedClass, float(predictedPropability))\n",
        "        cursor.execute(add_result, data_result)\n",
        "        result_id = cursor.lastrowid\n",
        "        \n",
        "        print(result_id, \" | \", fileName, \" | \", modelName, \" | \", predictedClass, \" | \", predictedPropability)\n",
        "       \n",
        "        cnx.commit()\n",
        "        \n",
        "        print(\"Now searching for similar words in ImageNet tree (parent / child search)\")\n",
        "        \n",
        "        expandResultsByImageNetTreeSearch(predictedClassSynsetId, localPath, modelName, predicationProbability)\n",
        "        \n",
        "  cursor.close()\n",
        "  cnx.close()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mysql-connector-python-rf\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/79/2ff01ab7aa08db3a16b70b990c579c1024c6b2a734263cc7513a758867de/mysql-connector-python-rf-2.2.2.tar.gz (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 3.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mysql-connector-python-rf\n",
            "  Building wheel for mysql-connector-python-rf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/58/fb/d95c84fad7e1bebfed324c13e107ebb08e1997c9226532859a\n",
            "Successfully built mysql-connector-python-rf\n",
            "Installing collected packages: mysql-connector-python-rf\n",
            "Successfully installed mysql-connector-python-rf-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1uiNs7vz1k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mysql-connector-python-rf\n",
        "\n",
        "import mysql.connector\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def querySearchWord(searchWord):\n",
        "  cnx = mysql.connector.connect(user='ml2', password='ml2@hsOg#2019!',\n",
        "                              host='192.52.33.218',\n",
        "                              database='ml2')\n",
        "  cursor = cnx.cursor()\n",
        "  query = (\"select distinct local_path, prediction_class from results where prediction_class = %s\")\n",
        "  \n",
        "  cursor.execute(query, (searchWord,))\n",
        "  \n",
        "  print(\"Found following files for your search word \\\"\" + searchWord + \"\\\":\")\n",
        "  \n",
        "  for (local_path, prediction_class) in cursor:\n",
        "    foundFiles = [open(local_path, 'rb')]\n",
        "    preparedImage224x224 = prepareImagesForClassification(foundFiles, 224, 224)[0]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(preparedImage224x224)\n",
        "    plt.title(\"{}\".format(local_path))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "  cursor.close()\n",
        "  cnx.close()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGUEio_cHH-E",
        "colab_type": "text"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn6JKxHDamCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "path = \"/tmp/image_classification\"\n",
        "hashrange = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_OUi5capDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparation: Delete local files\n",
        "deleteLocalFiles(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPwgqf54xz1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparation: Create local directory structure\n",
        "for i in range(hashrange):\n",
        "  if(i % 10 == 0):\n",
        "    parentPath = path + \"/\" + str((int)(i/10))\n",
        "    createLocalDirectory(parentPath)\n",
        "  normalizedI = '%02d' % i  # Normalization, pad zeroes\n",
        "  filePath = parentPath + \"/\" + normalizedI\n",
        "  createLocalDirectory(filePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvmx3NziAefN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "\n",
        "data = urlopen(\"https://raw.githubusercontent.com/ml2-picme/PicMe/master/input/images_subset.txt\")\n",
        "for line in data:\n",
        "  if not line.startswith(b'#'):  # Ignore Lines that begin with a comment (#)\n",
        "    line = line.decode(\"utf-8\").split(\"\\n\")[0]  # Normalization\n",
        "    url = line.split(\";\")[0]\n",
        "    label = line.split(\";\")[1]\n",
        "    \n",
        "    filename = getFileNameFromPath(url)\n",
        "\n",
        "    hashvalue = abs(hash(filename)) % hashrange\n",
        "    parent_dir = (int)(hashvalue / 10)\n",
        "    hashvalue = '%02d' % hashvalue  # Normalization, pad zeroes\n",
        "    \n",
        "    filetype = filename.split(\".\")[len(filename.split(\".\")) - 1]\n",
        "    newFilename = label + \".\" + filetype\n",
        "    #print(newFilename)\n",
        "\n",
        "    print(url, \" -> \", hashvalue, \" -> \", label, \" -> \", parent_dir, \" -> \", filename)\n",
        "\n",
        "    localPath = path + \"/\" + str(parent_dir) + \"/\" + hashvalue + \"/\" + newFilename\n",
        "\n",
        "    downloadFileFromUrl(url, localPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r124aQ3DELt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extensionsToCheck = [\".jpg\", \".png\", \".bmp\"]\n",
        "foundFiles = findFilesInPath(path, extensionsToCheck)\n",
        "\n",
        "for foundFile in foundFiles:\n",
        "  print(foundFile)\n",
        "\n",
        "preparedImages224x224 = prepareImagesForClassification(foundFiles, 224, 224)\n",
        "preparedImages299x299 = prepareImagesForClassification(foundFiles, 299, 299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9FO_yO_OtIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import *\n",
        "\n",
        "# Achtung: Hier werden Funktionen übergeben: \n",
        "# 1) preprocess_input Funktion\n",
        "# 2) decode_predictions Funktion\n",
        "# => Dies sorgt dafür, dass die gesamte Klassifizierung ausgelagert und dynamisch aufgerufen werden kann!\n",
        "\n",
        "predictedClassesVGG16 = classifyImages(preparedImages224x224, vgg16.preprocess_input, vgg16.decode_predictions, vgg16.VGG16(input_shape=(224, 224, 3)))\n",
        "predictedClassesVGG19 = classifyImages(preparedImages224x224, vgg19.preprocess_input, vgg19.decode_predictions, vgg19.VGG19(input_shape=(224, 224, 3)))\n",
        "predictedClassesMobileNetV2 = classifyImages(preparedImages224x224, mobilenet_v2.preprocess_input, mobilenet_v2.decode_predictions, mobilenet_v2.MobileNetV2(input_shape=(224, 224, 3)))\n",
        "predictedClassesResNet50 = classifyImages(preparedImages224x224, resnet50.preprocess_input, resnet50.decode_predictions, resnet50.ResNet50(input_shape=(224, 224, 3)))\n",
        "predictedClassesDenseNet201 = classifyImages(preparedImages224x224, densenet.preprocess_input, densenet.decode_predictions, densenet.DenseNet201(input_shape=(224, 224, 3)))\n",
        "predictedClassesInceptionV3 = classifyImages(preparedImages299x299, inception_v3.preprocess_input, inception_v3.decode_predictions, inception_v3.InceptionV3(input_shape=(299, 299, 3)))\n",
        "predictedClassesXception = classifyImages(preparedImages299x299, xception.preprocess_input, xception.decode_predictions, xception.Xception(input_shape=(299, 299, 3)))\n",
        "predictedClassesInceptionResNet = classifyImages(preparedImages299x299, inception_resnet_v2.preprocess_input, inception_resnet_v2.decode_predictions,inception_resnet_v2.InceptionResNetV2(input_shape=(299, 299, 3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKcAN4gcTcoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optional: Print the images with the predicted classes\n",
        "printClassificationResults(preparedImages224x224, predictedClassesVGG16)\n",
        "printClassificationResults(preparedImages224x224, predictedClassesVGG19)\n",
        "printClassificationResults(preparedImages224x224, predictedClassesMobileNetV2)\n",
        "printClassificationResults(preparedImages224x224, predictedClassesResNet50)\n",
        "printClassificationResults(preparedImages224x224, predictedClassesDenseNet201)\n",
        "printClassificationResults(preparedImages299x299, predictedClassesInceptionV3)\n",
        "printClassificationResults(preparedImages299x299, predictedClassesXception)\n",
        "printClassificationResults(preparedImages299x299, predictedClassesInceptionResNet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe_DG_JXbBPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultsList = [predictedClassesVGG16, predictedClassesVGG19, predictedClassesMobileNetV2, predictedClassesResNet50, predictedClassesDenseNet201, predictedClassesInceptionV3, predictedClassesXception, predictedClassesInceptionResNet]\n",
        "modelList = ['VGG16', 'VGG19', 'MobileNetV2', 'ResNet50', 'DenseNet201', 'InceptionV3', 'Xception', 'InceptionResNet']\n",
        "\n",
        "# Diese compareResults Methode braucht 4 Parameter:\n",
        "# 1. Die Liste der Dateinamen\n",
        "# 2. Die Ergebnisse der einzelnen Modellen, als Array zusammengefasst\n",
        "# 3. Die Namen der Modelle, einfach als String Array\n",
        "# 4. Threshold (mind. Sicherheit der Modellvorhersage) => nach Treffen am 17.04. auf 0.0 gesetzt (= kein Filter)\n",
        "compareResults(foundFiles, resultsList, modelList, 0.00)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoLUm-ThbBbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allResultsCsv = generateCsvForModelComparison(foundFiles, resultsList, modelList)\n",
        "\n",
        "for result in allResultsCsv:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX64ZDMv8Iw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "storeResultsToDB(foundFiles, resultsList, modelList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECBdN-SU82I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "querySearchWord(\"bucket\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}