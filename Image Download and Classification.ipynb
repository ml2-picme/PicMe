{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Download and Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ml2-picme/PicMe/blob/master/Image%20Download%20and%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWATd4KNHBwU",
        "colab_type": "text"
      },
      "source": [
        "## 1. Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwSEw0m3DFes",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Needed libraries for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VD4ZF_JDJVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import hashlib\n",
        "from urllib.request import urlopen\n",
        "from keras.applications import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDfdkaX1Qlie",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Install needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLLCiLkfQoWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mysql-connector-python-rf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceaDnZ0-CkO0",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Clone the Github Project itself, to be able to add the functions defined in the ./scripts sub-directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZhkZPmugh1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove Path if already existing locally\n",
        "!rm -r PicMe\n",
        "\n",
        "# Clone Git repository\n",
        "!git clone https://github.com/ml2-picme/PicMe.git\n",
        "\n",
        "# Add the relevant paths of the repo to system path\n",
        "sys.path.append(\"/content/PicMe\")\n",
        "sys.path.append(\"/content/PicMe/scripts\")\n",
        "\n",
        "# Add the functions, defined in the script files\n",
        "from db_connector import *\n",
        "from file_processing import *\n",
        "from image_classification import *\n",
        "from imagenet_tree_search import *\n",
        "from text_processing import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGUEio_cHH-E",
        "colab_type": "text"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn6JKxHDamCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "path = \"/tmp/image_classification\"\n",
        "hashrange = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_OUi5capDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparation: Delete local files\n",
        "deleteLocalDirectory(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPwgqf54xz1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparation: Create local directory structure\n",
        "for i in range(hashrange):\n",
        "  if(i % 10 == 0):\n",
        "    parentPath = path + \"/\" + str((int)(i/10))\n",
        "    createLocalDirectory(parentPath)\n",
        "  normalizedI = '%02d' % i  # Normalization, pad zeroes\n",
        "  filePath = parentPath + \"/\" + normalizedI\n",
        "  createLocalDirectory(filePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvmx3NziAefN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filesDict = {}\n",
        "\n",
        "data = urlopen(\"https://raw.githubusercontent.com/ml2-picme/PicMe/master/input/images_subset.txt\")\n",
        "for line in data:\n",
        "  if not line.startswith(b'#'):  # Ignore Lines that begin with a comment (#)\n",
        "    line = line.decode(\"utf-8\").split(\"\\n\")[0]  # Normalization\n",
        "    url = line.split(\";\")[0]\n",
        "    label = line.split(\";\")[1]\n",
        "    \n",
        "    filename = getFileNameFromPath(url)\n",
        "\n",
        "    hashvalue = int(hashlib.sha1(filename.encode('utf-8')).hexdigest(), 16) % hashrange\n",
        "    parent_dir = (int)(hashvalue / 10)\n",
        "    hashvalue = '%02d' % hashvalue  # Normalization, pad zeroes\n",
        "    \n",
        "    filetype = filename.split(\".\")[len(filename.split(\".\")) - 1]\n",
        "    newFilename = label + \".\" + filetype\n",
        "    #print(newFilename)\n",
        "\n",
        "    print(url, \" -> \", hashvalue, \" -> \", label, \" -> \", parent_dir, \" -> \", filename)\n",
        "\n",
        "    localPath = path + \"/\" + str(parent_dir) + \"/\" + hashvalue + \"/\" + newFilename\n",
        "\n",
        "    downloadFileFromUrl(url, localPath)\n",
        "    \n",
        "    filesDict[localPath] = url\n",
        "    \n",
        "for x, y in filesDict.items():\n",
        "  print(x, \"->\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r124aQ3DELt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extensionsToCheck = [\".jpg\", \".png\", \".bmp\"]\n",
        "foundFiles = findFilesInPathByFileExtension(path, extensionsToCheck)\n",
        "\n",
        "for foundFile in foundFiles:\n",
        "  print(foundFile)\n",
        "\n",
        "preparedImages224x224 = prepareImagesForClassification(foundFiles, 224, 224)\n",
        "preparedImages299x299 = prepareImagesForClassification(foundFiles, 299, 299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9FO_yO_OtIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Achtung: Hier werden Funktionen übergeben: \n",
        "# 1) preprocess_input Funktion\n",
        "# 2) decode_predictions Funktion\n",
        "# => Dies sorgt dafür, dass die gesamte Klassifizierung ausgelagert und dynamisch aufgerufen werden kann!\n",
        "\n",
        "predictedClassesVGG16 = classifyImages(preparedImages224x224, vgg16.preprocess_input, vgg16.decode_predictions, vgg16.VGG16(input_shape=(224, 224, 3)))\n",
        "predictedClassesVGG19 = classifyImages(preparedImages224x224, vgg19.preprocess_input, vgg19.decode_predictions, vgg19.VGG19(input_shape=(224, 224, 3)))\n",
        "#predictedClassesMobileNetV2 = classifyImages(preparedImages224x224, mobilenet_v2.preprocess_input, mobilenet_v2.decode_predictions, mobilenet_v2.MobileNetV2(input_shape=(224, 224, 3)))\n",
        "#predictedClassesResNet50 = classifyImages(preparedImages224x224, resnet50.preprocess_input, resnet50.decode_predictions, resnet50.ResNet50(input_shape=(224, 224, 3)))\n",
        "#predictedClassesDenseNet201 = classifyImages(preparedImages224x224, densenet.preprocess_input, densenet.decode_predictions, densenet.DenseNet201(input_shape=(224, 224, 3)))\n",
        "#predictedClassesInceptionV3 = classifyImages(preparedImages299x299, inception_v3.preprocess_input, inception_v3.decode_predictions, inception_v3.InceptionV3(input_shape=(299, 299, 3)))\n",
        "#predictedClassesXception = classifyImages(preparedImages299x299, xception.preprocess_input, xception.decode_predictions, xception.Xception(input_shape=(299, 299, 3)))\n",
        "#predictedClassesInceptionResNet = classifyImages(preparedImages299x299, inception_resnet_v2.preprocess_input, inception_resnet_v2.decode_predictions,inception_resnet_v2.InceptionResNetV2(input_shape=(299, 299, 3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe_DG_JXbBPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultsList = [predictedClassesVGG16, predictedClassesVGG19]#, predictedClassesMobileNetV2, predictedClassesResNet50, predictedClassesDenseNet201, predictedClassesInceptionV3, predictedClassesXception, predictedClassesInceptionResNet]\n",
        "modelList = ['VGG16', 'VGG19']#, 'MobileNetV2', 'ResNet50', 'DenseNet201', 'InceptionV3', 'Xception', 'InceptionResNet']\n",
        "\n",
        "# Diese compareResults Methode braucht 4 Parameter:\n",
        "# 1. Die Liste der Dateinamen\n",
        "# 2. Die Ergebnisse der einzelnen Modellen, als Array zusammengefasst\n",
        "# 3. Die Namen der Modelle, einfach als String Array\n",
        "# 4. Threshold (mind. Sicherheit der Modellvorhersage) => nach Treffen am 17.04. auf 0.0 gesetzt (= kein Filter)\n",
        "compareResults(foundFiles, resultsList, modelList, 0.00, preparedImages299x299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoLUm-ThbBbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allResultsCsv = generateCsvForModelComparison(foundFiles, resultsList, modelList, filesDict, getFileNameFromPath)\n",
        "\n",
        "for result in allResultsCsv:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyvyLDuwYa3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbConnection = createConnection()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX64ZDMv8Iw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# DB stuff\n",
        "\n",
        "parentToChildrenDictionary = getParentToChildrenDictionary()\n",
        "childToParentsDictionary = getChildToParentsDictionary()\n",
        "\n",
        "# Iterating the classification results:\n",
        "for k in range(len(modelList)):\n",
        "    print(\"==== other model =====\")\n",
        "    for i in range(len(foundFiles)):\n",
        "      print(\"==== other file =====\")\n",
        "      for j in range(5):\n",
        "        print(\"Counter:\")\n",
        "        print(\"Model\", (k+1), \"of\", len(modelList))\n",
        "        print(\"File\", (i+1), \"of\", len(foundFiles))\n",
        "        print(\"Top\", (j+1), \"of\", 5)\n",
        "\n",
        "        fileName = foundFiles[i]\n",
        "        modelName = modelList[k]\n",
        "        predictedClassSynsetId = resultsList[k][i][j][0]\n",
        "        predictedClass = resultsList[k][i][j][1]\n",
        "        predictedProbability = resultsList[k][i][j][2]\n",
        "\n",
        "        # Store the original class to DB\n",
        "        storeImageClassificationResultToDB(dbConnection, fileName, modelName, predictedClass, predictedProbability)\n",
        "        \n",
        "        # Expand ImageNet classes by ImageNet tree search\n",
        "        newWords = getWords(predictedClassSynsetId, parentToChildrenDictionary, childToParentsDictionary)\n",
        "        \n",
        "        # Also save these new results to DB\n",
        "        for newWord in newWords:\n",
        "          storeImageClassificationResultToDB(dbConnection, fileName, modelName, newWord, predictedProbability)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECBdN-SU82I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultCursor = querySearchWordAndPrintResults(dbConnection, \"tutti-frutti\", prepareImagesForClassification)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qO6qUcKZvBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultCursor = querySearchWordAndPrintResults(dbConnection, \"indigo bunting\", prepareImagesForClassification)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}