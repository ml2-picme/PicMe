{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Download and Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ml2-picme/PicMe/blob/master/Image%20Download%20and%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWATd4KNHBwU",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B9Fhk2t8sFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b2a05935-5918-41e1-e766-89d71586110c"
      },
      "source": [
        "# contact: tai.truong@software-developer.org\n",
        "\n",
        "import nltk\n",
        "# regular expression\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('porter_test')\n",
        "# get all english stop words like 'the', 'is', 'are', 'over'\n",
        "stopWords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "# returns a list of filtered words\n",
        "def normalizeWords(input):\n",
        "  # source: https://www.kdnuggets.com/2018/03/simple-text-classifier-google-colaboratory.html\n",
        "  # replace all non-letters to whitespace. Example: hello#!world => hello  world\n",
        "  input = re.sub('[^a-zA-Z]', ' ',  str(input))\n",
        "  # replace non unicode words (\\w), unicode digits (\\d), or unicode whitespaces with whitespace\n",
        "  input = re.sub(r'[^\\w\\d\\s]', ' ', input)\n",
        "  # replace trailing whitespaces into one whitespace\n",
        "  input = re.sub(r'\\s+', ' ', input)\n",
        "  # make lowercase\n",
        "  input = re.sub(r'^\\s+|\\s+?$', '', input.lower())\n",
        "\n",
        "  filteredWords = []\n",
        "  for word in input.split():\n",
        "    if word not in stopWords:\n",
        "      filteredWords.append(word)\n",
        "  return filteredWords\n",
        "\n",
        "def stem(list):\n",
        "  ps = nltk.PorterStemmer()\n",
        "  stemmedList = []\n",
        "  for word in list:\n",
        "    stemmedList.append(ps.stem(word))\n",
        "  return stemmedList\n",
        "\n",
        "def match(inputText, searchTermList):\n",
        "  normalized = filterWords(input)\n",
        "  stemmed = stem(normalized)\n",
        "  stemmedSearchTermList = stem(searchTermList)\n",
        "  match = []\n",
        "  for word in stemmed:\n",
        "    if word in stemmedSearchTermList:\n",
        "      index = stemmed.index(word)\n",
        "      match.append(normalized[index])\n",
        "  return match\n",
        "\n",
        "# test code\n",
        "input = 'the quick brown foxes 123 jumped ❤☀ over äääßßß the lAzy Dog!'\n",
        "print('input:', input)\n",
        "normalized = filterWords(input)\n",
        "print('normalized: ', normalized)\n",
        "stemmed = stem(normalized)\n",
        "print('stemmed: ', stemmed)\n",
        "searchTermList = ['fox', 'dogs', 'cat']\n",
        "stemmedSearchTermList = stem(searchTermList)\n",
        "print('stemmed search terms: ', stemmedSearchTermList)\n",
        "match(input, searchTermList)\n",
        "print('match: ', match(input, searchTermList))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]   Package porter_test is already up-to-date!\n",
            "input: the quick brown foxes 123 jumped ❤☀ over äääßßß the lAzy Dog!\n",
            "normalized:  ['quick', 'brown', 'foxes', 'jumped', 'lazy', 'dog']\n",
            "stemmed:  ['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']\n",
            "stemmed search terms:  ['fox', 'dog', 'cat']\n",
            "match:  ['foxes', 'dog']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZhkZPmugh1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "\n",
        "!rm -r PicMe\n",
        "!git clone https://github.com/ml2-picme/PicMe.git\n",
        "\n",
        "sys.path.append(\"/content/PicMe\")\n",
        "\n",
        "from imagenet_processing_script import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPPEz73oL5d2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parentToChildrenDictionary = getParentToChildrenDictionary()\n",
        "childToParentsDictionary = getChildToParentsDictionary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ip5024YJyM7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expandResultsByImageNetTreeSearch(synsetId, localPath, modelName, predicationProbability):\n",
        "  results = getWords(synsetId, parentToChildrenDictionary, childToParentsDictionary)\n",
        "  \n",
        "  cnx = mysql.connector.connect(user='ml2', password='ml2@hsOg#2019!',\n",
        "                              host='192.52.33.218',\n",
        "                              database='ml2',\n",
        "                              autocommit=True)\n",
        "  cursor = cnx.cursor()\n",
        "  add_result = (\"insert ignore into results (local_path, model, prediction_class, prediction_probability) values (%s, %s, %s, %s)\")\n",
        "  \n",
        "  for result in results:\n",
        "    data_result = (localPath, modelName, result, float(predicationProbability))\n",
        "    cursor.execute(add_result, data_result)\n",
        "    result_id = cursor.lastrowid\n",
        "        \n",
        "    print(result_id, \" | \", localPath, \" | \", modelName, \" | \", result, \" | \", predicationProbability)\n",
        "       \n",
        "    cnx.commit()\n",
        "        \n",
        "  cursor.close()\n",
        "  cnx.close()\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "398aFKJTvUoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "import urllib.request\n",
        "\n",
        "def downloadFileFromUrl(URL, localPath):\n",
        "  print(\"Lade \", URL, \" nach \", localPath + \" herunter\")\n",
        "  with urllib.request.urlopen(URL) as url:\n",
        "    with open(localPath, 'wb') as f:\n",
        "      f.write(url.read())\n",
        "  load_img(localPath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPloOvoFfV0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFileNameFromPath(path):\n",
        "  filename = path.split(\"/\")[len(path.split(\"/\")) - 1]\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvdJC02-ym56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def createLocalDirectory(dir):\n",
        "  \n",
        "  print(\"Erstelle lokales Verzeichnis:\", dir, end='\\t')\n",
        "  \n",
        "  try:  \n",
        "    os.makedirs(dir)\n",
        "\n",
        "  except OSError:  \n",
        "    print (\" - Failed\")\n",
        "  else:\n",
        "    print(\" - OK\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQwnQjoAUzlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def deleteLocalFiles(dir):\n",
        "  try:\n",
        "    print(\"Delete local files\", end='')  \n",
        "    shutil.rmtree(dir) \n",
        "    print(\" - OK\")\n",
        "  except OSError:\n",
        "    print(\" - Failed\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J20r1OB-DeU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def findFilesInPath(dir, extensions):\n",
        "\n",
        "  files = []\n",
        "  \n",
        "  # r=root, d=directories, f = files\n",
        "  for r, d, f in os.walk(dir):\n",
        "    for file in f:\n",
        "      for extension in extensions:\n",
        "        if file.lower().endswith(extension.lower()):\n",
        "            files.append(os.path.join(r, file))\n",
        "            break\n",
        "            \n",
        "  return files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5htsSXuNp-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def prepareImagesForClassification(files, sizeX, sizeY):\n",
        "  images = []\n",
        "  \n",
        "  for file in files:\n",
        "    try:\n",
        "      image = Image.open(file)\n",
        "      image = image.resize((sizeX, sizeY), Image.LANCZOS)\n",
        "      image = image.convert(\"RGB\")\n",
        "      \n",
        "      image = np.asarray(image)\n",
        "      images.append(image)\n",
        "    except OSError:\n",
        "      pass\n",
        "  \n",
        "  images = np.asarray(images)\n",
        "  return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcmDx_BHR9uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classifyImages(preparedImages, preprocess_input_function, decode_predictions_function, model):\n",
        "  \n",
        "  # preprocess the images to fit to the model\n",
        "  images_preprocessed = preprocess_input_function(preparedImages)\n",
        "  \n",
        "  # use the model to classifi the images\n",
        "  images_pred = model.predict(images_preprocessed, verbose=1)\n",
        "  \n",
        "  pred_results = decode_predictions_function(images_pred)\n",
        "  \n",
        "  return pred_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znYMR5HZbLCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compareResults(fileNames, resulsList, modelList, threshold, images):\n",
        "  \n",
        "  for i in range(len(fileNames)):\n",
        "    print(\"Comparing the Results for File: \" + fileNames[i])\n",
        "    plt.figure()\n",
        "    plt.imshow(images[i])\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "    \n",
        "    for j in range(5):\n",
        "      for k in range(len(modelList)):\n",
        "        resultToPrint = resultsList[k][i][j]\n",
        "        \n",
        "        # Setze 5% als Threshold\n",
        "        if(resultToPrint is not None and resultToPrint[2] > threshold):\n",
        "          print(\" > \", (j+1), \". Platz @ \", modelList[k], \" : \", resultsList[k][i][j])\n",
        "        else:\n",
        "          print(\" > \", (j+1), \". Platz @ \", modelList[k], \" : \", \"--- Threshold-Filter ---\")\n",
        "      \n",
        "      print(\"=================================================================\")\n",
        "      \n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdV9RhtdUyks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generateCsvForModelComparison(fileNames, resulsList, modelList, filesDict):\n",
        "  allModelCSVs = []\n",
        "  \n",
        "  for k in range(len(modelList)):\n",
        "    modelCSV = \"URL\"\n",
        "    for i in range(len(fileNames)):\n",
        "      modelCSV += \";\" + \"=HYPERLINK(\\\"\" + filesDict[fileNames[i]] + \"\\\")\"\n",
        "  \n",
        "    modelCSV += \"\\n\"\n",
        "    modelCSV += modelList[k]\n",
        "    \n",
        "    for i in range(len(fileNames)):\n",
        "      modelCSV += \";\" + getFileNameFromPath(fileNames[i])\n",
        "      \n",
        "    modelCSV += \"\\n\"\n",
        "    \n",
        "    for j in range(5):\n",
        "      modelCSV += str(j+1) + \".Platz\"\n",
        "      \n",
        "      for i in range(len(fileNames)):\n",
        "        modelCSV += \";\" + str(resultsList[k][i][j][1])\n",
        "        \n",
        "      modelCSV += \"\\n\"\n",
        "      \n",
        "    allModelCSVs.append(modelCSV)\n",
        "        \n",
        "  return allModelCSVs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grH2Hwr65Tvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MySQL Part -> Writing Image Classification Results to DB\n",
        "!pip install mysql-connector-python-rf\n",
        "\n",
        "import mysql.connector\n",
        "\n",
        "def storeResultsToDB(fileNames, resultsList, modelList):\n",
        "  \n",
        "  cnx = mysql.connector.connect(user='ml2', password='ml2@hsOg#2019!',\n",
        "                              host='192.52.33.218',\n",
        "                              database='ml2',\n",
        "                              autocommit=True)\n",
        "  cursor = cnx.cursor()\n",
        "  add_result = (\"insert ignore into results (local_path, model, prediction_class, prediction_probability) values (%s, %s, %s, %s)\")\n",
        "  \n",
        "  for k in range(len(modelList)):\n",
        "    \n",
        "    print(\"==== other model =====\")\n",
        "    \n",
        "    for i in range(len(fileNames)):\n",
        "      \n",
        "      print(\"==== other file =====\")\n",
        "      \n",
        "      for j in range(5):\n",
        "        \n",
        "        print(\"Counter:\")\n",
        "        print(\"Model\", (k+1), \"von\", len(modelList))\n",
        "        print(\"File\", (i+1), \"von\", len(fileNames))\n",
        "        print(\"Platz\", (j+1), \"von\", 5)\n",
        "        \n",
        "        fileName = fileNames[i]\n",
        "        modelName = modelList[k]\n",
        "        predictedClassSynsetId = resultsList[k][i][j][0]\n",
        "        predictedClass = resultsList[k][i][j][1]\n",
        "        predictedPropability = resultsList[k][i][j][2]\n",
        "  \n",
        "        #print(fileName)\n",
        "        #print(modelName)\n",
        "        #print(predictedClass)\n",
        "        #print(predictedPropability)\n",
        "        #print(\"==============\")\n",
        "        \n",
        "        data_result = (fileName, modelName, predictedClass, float(predictedPropability))\n",
        "        cursor.execute(add_result, data_result)\n",
        "        result_id = cursor.lastrowid\n",
        "        \n",
        "        print(result_id, \" | \", fileName, \" | \", modelName, \" | \", predictedClass, \" | \", predictedPropability)\n",
        "       \n",
        "        cnx.commit()\n",
        "        \n",
        "        print(\"Now searching for similar words in ImageNet tree (parent / child search)\")\n",
        "        \n",
        "        expandResultsByImageNetTreeSearch(predictedClassSynsetId, fileName, modelName, predictedPropability)\n",
        "        \n",
        "  cursor.close()\n",
        "  cnx.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1uiNs7vz1k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mysql-connector-python-rf\n",
        "\n",
        "import mysql.connector\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def querySearchWord(searchWord):\n",
        "  cnx = mysql.connector.connect(user='ml2', password='ml2@hsOg#2019!',\n",
        "                              host='192.52.33.218',\n",
        "                              database='ml2',\n",
        "                              autocommit=True)\n",
        "  cursor = cnx.cursor()\n",
        "  query = (\"select distinct local_path, prediction_class from results where prediction_class = %s\")\n",
        "  \n",
        "  cursor.execute(query, (searchWord,))\n",
        "  \n",
        "  print(\"Found following files for your search word \\\"\" + searchWord + \"\\\":\")\n",
        "  \n",
        "  for (local_path, prediction_class) in cursor:\n",
        "    foundFiles = [open(local_path, 'rb')]\n",
        "    preparedImage224x224 = prepareImagesForClassification(foundFiles, 224, 224)[0]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.imshow(preparedImage224x224)\n",
        "    plt.title(\"{}\".format(local_path))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "  cursor.close()\n",
        "  cnx.close()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGUEio_cHH-E",
        "colab_type": "text"
      },
      "source": [
        "## Logic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn6JKxHDamCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "path = \"/tmp/image_classification\"\n",
        "hashrange = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_OUi5capDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparation: Delete local files\n",
        "deleteLocalFiles(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPwgqf54xz1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparation: Create local directory structure\n",
        "for i in range(hashrange):\n",
        "  if(i % 10 == 0):\n",
        "    parentPath = path + \"/\" + str((int)(i/10))\n",
        "    createLocalDirectory(parentPath)\n",
        "  normalizedI = '%02d' % i  # Normalization, pad zeroes\n",
        "  filePath = parentPath + \"/\" + normalizedI\n",
        "  createLocalDirectory(filePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvmx3NziAefN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlopen\n",
        "\n",
        "filesDict = {}\n",
        "\n",
        "data = urlopen(\"https://raw.githubusercontent.com/ml2-picme/PicMe/master/input/images.txt\")\n",
        "for line in data:\n",
        "  if not line.startswith(b'#'):  # Ignore Lines that begin with a comment (#)\n",
        "    line = line.decode(\"utf-8\").split(\"\\n\")[0]  # Normalization\n",
        "    url = line.split(\";\")[0]\n",
        "    label = line.split(\";\")[1]\n",
        "    \n",
        "    filename = getFileNameFromPath(url)\n",
        "\n",
        "    hashvalue = abs(hash(filename)) % hashrange\n",
        "    parent_dir = (int)(hashvalue / 10)\n",
        "    hashvalue = '%02d' % hashvalue  # Normalization, pad zeroes\n",
        "    \n",
        "    filetype = filename.split(\".\")[len(filename.split(\".\")) - 1]\n",
        "    newFilename = label + \".\" + filetype\n",
        "    #print(newFilename)\n",
        "\n",
        "    print(url, \" -> \", hashvalue, \" -> \", label, \" -> \", parent_dir, \" -> \", filename)\n",
        "\n",
        "    localPath = path + \"/\" + str(parent_dir) + \"/\" + hashvalue + \"/\" + newFilename\n",
        "\n",
        "    downloadFileFromUrl(url, localPath)\n",
        "    \n",
        "    filesDict[localPath] = url\n",
        "    \n",
        "for x, y in filesDict.items():\n",
        "  print(x, \"->\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r124aQ3DELt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extensionsToCheck = [\".jpg\", \".png\", \".bmp\"]\n",
        "foundFiles = findFilesInPath(path, extensionsToCheck)\n",
        "\n",
        "for foundFile in foundFiles:\n",
        "  print(foundFile)\n",
        "\n",
        "preparedImages224x224 = prepareImagesForClassification(foundFiles, 224, 224)\n",
        "preparedImages299x299 = prepareImagesForClassification(foundFiles, 299, 299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9FO_yO_OtIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import *\n",
        "\n",
        "# Achtung: Hier werden Funktionen übergeben: \n",
        "# 1) preprocess_input Funktion\n",
        "# 2) decode_predictions Funktion\n",
        "# => Dies sorgt dafür, dass die gesamte Klassifizierung ausgelagert und dynamisch aufgerufen werden kann!\n",
        "\n",
        "predictedClassesVGG16 = classifyImages(preparedImages224x224, vgg16.preprocess_input, vgg16.decode_predictions, vgg16.VGG16(input_shape=(224, 224, 3)))\n",
        "predictedClassesVGG19 = classifyImages(preparedImages224x224, vgg19.preprocess_input, vgg19.decode_predictions, vgg19.VGG19(input_shape=(224, 224, 3)))\n",
        "predictedClassesMobileNetV2 = classifyImages(preparedImages224x224, mobilenet_v2.preprocess_input, mobilenet_v2.decode_predictions, mobilenet_v2.MobileNetV2(input_shape=(224, 224, 3)))\n",
        "predictedClassesResNet50 = classifyImages(preparedImages224x224, resnet50.preprocess_input, resnet50.decode_predictions, resnet50.ResNet50(input_shape=(224, 224, 3)))\n",
        "predictedClassesDenseNet201 = classifyImages(preparedImages224x224, densenet.preprocess_input, densenet.decode_predictions, densenet.DenseNet201(input_shape=(224, 224, 3)))\n",
        "predictedClassesInceptionV3 = classifyImages(preparedImages299x299, inception_v3.preprocess_input, inception_v3.decode_predictions, inception_v3.InceptionV3(input_shape=(299, 299, 3)))\n",
        "predictedClassesXception = classifyImages(preparedImages299x299, xception.preprocess_input, xception.decode_predictions, xception.Xception(input_shape=(299, 299, 3)))\n",
        "predictedClassesInceptionResNet = classifyImages(preparedImages299x299, inception_resnet_v2.preprocess_input, inception_resnet_v2.decode_predictions,inception_resnet_v2.InceptionResNetV2(input_shape=(299, 299, 3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe_DG_JXbBPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "resultsList = [predictedClassesVGG16, predictedClassesVGG19, predictedClassesMobileNetV2, predictedClassesResNet50, predictedClassesDenseNet201, predictedClassesInceptionV3, predictedClassesXception, predictedClassesInceptionResNet]\n",
        "modelList = ['VGG16', 'VGG19', 'MobileNetV2', 'ResNet50', 'DenseNet201', 'InceptionV3', 'Xception', 'InceptionResNet']\n",
        "\n",
        "# Diese compareResults Methode braucht 4 Parameter:\n",
        "# 1. Die Liste der Dateinamen\n",
        "# 2. Die Ergebnisse der einzelnen Modellen, als Array zusammengefasst\n",
        "# 3. Die Namen der Modelle, einfach als String Array\n",
        "# 4. Threshold (mind. Sicherheit der Modellvorhersage) => nach Treffen am 17.04. auf 0.0 gesetzt (= kein Filter)\n",
        "compareResults(foundFiles, resultsList, modelList, 0.00, preparedImages299x299)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoLUm-ThbBbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allResultsCsv = generateCsvForModelComparison(foundFiles, resultsList, modelList, filesDict)\n",
        "\n",
        "for result in allResultsCsv:\n",
        "  print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX64ZDMv8Iw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "storeResultsToDB(foundFiles, resultsList, modelList)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECBdN-SU82I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "querySearchWord(\"bucket\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}